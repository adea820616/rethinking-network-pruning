{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_cuda=True\n",
    "args_batch_size=64\n",
    "\n",
    "args_dataset='cifar10'\n",
    "args_depth = 110\n",
    "args_arch = 'resnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args_cuda else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('/home/jovyan/model_compression/rethinking-network-pruning/cifar/l1-norm-pruning/data.cifar10', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Pad(4),\n",
    "                       transforms.RandomCrop(32),\n",
    "                       transforms.RandomHorizontalFlip(),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                   ])),\n",
    "    batch_size=args_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# train_set = datasets.CIFAR10('/home/jovyan/model_compression/rethinking-network-pruning/cifar/l1-norm-pruning/data.cifar10', train=True, download=True,)\n",
    "# loader = torch.utils.data.DataLoader(train_set, batch_size=len(train_set), shuffle=True, **kwargs)\n",
    "# data = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([4, 4, 5, 9, 1, 8, 5, 6, 0, 1, 5, 0, 9, 3, 0, 7, 9, 5, 1, 5, 8, 4, 1, 4,\n",
      "        6, 3, 0, 7, 6, 9, 0, 3, 8, 2, 6, 3, 6, 1, 0, 3, 6, 2, 8, 3, 5, 0, 7, 0,\n",
      "        1, 9, 8, 6, 2, 5, 3, 3, 6, 0, 6, 7, 2, 5, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print(batch_idx)\n",
    "#     print(data)\n",
    "    print(target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 32, 32])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: /home/jovyan/model_compression/rethinking-network-pruning/cifar/l1-norm-pruning/data.cifar10\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Pad(padding=4, fill=0, padding_mode=constant)\n",
       "               RandomCrop(size=(32, 32), padding=None)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
       "           )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  np.ones((3, 32, 32))\n",
    "w = np.ones((25, 5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 5 is different from 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-c4ebe8684084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 5 is different from 32)"
     ]
    }
   ],
   "source": [
    "y = np.matmul(x,w)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.__dict__[args_arch](dataset=args_dataset, depth=args_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "bn1.weight\n",
      "bn1.bias\n",
      "bn1.running_mean\n",
      "bn1.running_var\n",
      "bn1.num_batches_tracked\n",
      "layer1.0.conv1.weight\n",
      "layer1.0.bn1.weight\n",
      "layer1.0.bn1.bias\n",
      "layer1.0.bn1.running_mean\n",
      "layer1.0.bn1.running_var\n",
      "layer1.0.bn1.num_batches_tracked\n",
      "layer1.0.conv2.weight\n",
      "layer1.0.bn2.weight\n",
      "layer1.0.bn2.bias\n",
      "layer1.0.bn2.running_mean\n",
      "layer1.0.bn2.running_var\n",
      "layer1.0.bn2.num_batches_tracked\n",
      "layer1.1.conv1.weight\n",
      "layer1.1.bn1.weight\n",
      "layer1.1.bn1.bias\n",
      "layer1.1.bn1.running_mean\n",
      "layer1.1.bn1.running_var\n",
      "layer1.1.bn1.num_batches_tracked\n",
      "layer1.1.conv2.weight\n",
      "layer1.1.bn2.weight\n",
      "layer1.1.bn2.bias\n",
      "layer1.1.bn2.running_mean\n",
      "layer1.1.bn2.running_var\n",
      "layer1.1.bn2.num_batches_tracked\n",
      "layer1.2.conv1.weight\n",
      "layer1.2.bn1.weight\n",
      "layer1.2.bn1.bias\n",
      "layer1.2.bn1.running_mean\n",
      "layer1.2.bn1.running_var\n",
      "layer1.2.bn1.num_batches_tracked\n",
      "layer1.2.conv2.weight\n",
      "layer1.2.bn2.weight\n",
      "layer1.2.bn2.bias\n",
      "layer1.2.bn2.running_mean\n",
      "layer1.2.bn2.running_var\n",
      "layer1.2.bn2.num_batches_tracked\n",
      "layer1.3.conv1.weight\n",
      "layer1.3.bn1.weight\n",
      "layer1.3.bn1.bias\n",
      "layer1.3.bn1.running_mean\n",
      "layer1.3.bn1.running_var\n",
      "layer1.3.bn1.num_batches_tracked\n",
      "layer1.3.conv2.weight\n",
      "layer1.3.bn2.weight\n",
      "layer1.3.bn2.bias\n",
      "layer1.3.bn2.running_mean\n",
      "layer1.3.bn2.running_var\n",
      "layer1.3.bn2.num_batches_tracked\n",
      "layer1.4.conv1.weight\n",
      "layer1.4.bn1.weight\n",
      "layer1.4.bn1.bias\n",
      "layer1.4.bn1.running_mean\n",
      "layer1.4.bn1.running_var\n",
      "layer1.4.bn1.num_batches_tracked\n",
      "layer1.4.conv2.weight\n",
      "layer1.4.bn2.weight\n",
      "layer1.4.bn2.bias\n",
      "layer1.4.bn2.running_mean\n",
      "layer1.4.bn2.running_var\n",
      "layer1.4.bn2.num_batches_tracked\n",
      "layer1.5.conv1.weight\n",
      "layer1.5.bn1.weight\n",
      "layer1.5.bn1.bias\n",
      "layer1.5.bn1.running_mean\n",
      "layer1.5.bn1.running_var\n",
      "layer1.5.bn1.num_batches_tracked\n",
      "layer1.5.conv2.weight\n",
      "layer1.5.bn2.weight\n",
      "layer1.5.bn2.bias\n",
      "layer1.5.bn2.running_mean\n",
      "layer1.5.bn2.running_var\n",
      "layer1.5.bn2.num_batches_tracked\n",
      "layer1.6.conv1.weight\n",
      "layer1.6.bn1.weight\n",
      "layer1.6.bn1.bias\n",
      "layer1.6.bn1.running_mean\n",
      "layer1.6.bn1.running_var\n",
      "layer1.6.bn1.num_batches_tracked\n",
      "layer1.6.conv2.weight\n",
      "layer1.6.bn2.weight\n",
      "layer1.6.bn2.bias\n",
      "layer1.6.bn2.running_mean\n",
      "layer1.6.bn2.running_var\n",
      "layer1.6.bn2.num_batches_tracked\n",
      "layer1.7.conv1.weight\n",
      "layer1.7.bn1.weight\n",
      "layer1.7.bn1.bias\n",
      "layer1.7.bn1.running_mean\n",
      "layer1.7.bn1.running_var\n",
      "layer1.7.bn1.num_batches_tracked\n",
      "layer1.7.conv2.weight\n",
      "layer1.7.bn2.weight\n",
      "layer1.7.bn2.bias\n",
      "layer1.7.bn2.running_mean\n",
      "layer1.7.bn2.running_var\n",
      "layer1.7.bn2.num_batches_tracked\n",
      "layer1.8.conv1.weight\n",
      "layer1.8.bn1.weight\n",
      "layer1.8.bn1.bias\n",
      "layer1.8.bn1.running_mean\n",
      "layer1.8.bn1.running_var\n",
      "layer1.8.bn1.num_batches_tracked\n",
      "layer1.8.conv2.weight\n",
      "layer1.8.bn2.weight\n",
      "layer1.8.bn2.bias\n",
      "layer1.8.bn2.running_mean\n",
      "layer1.8.bn2.running_var\n",
      "layer1.8.bn2.num_batches_tracked\n",
      "layer1.9.conv1.weight\n",
      "layer1.9.bn1.weight\n",
      "layer1.9.bn1.bias\n",
      "layer1.9.bn1.running_mean\n",
      "layer1.9.bn1.running_var\n",
      "layer1.9.bn1.num_batches_tracked\n",
      "layer1.9.conv2.weight\n",
      "layer1.9.bn2.weight\n",
      "layer1.9.bn2.bias\n",
      "layer1.9.bn2.running_mean\n",
      "layer1.9.bn2.running_var\n",
      "layer1.9.bn2.num_batches_tracked\n",
      "layer1.10.conv1.weight\n",
      "layer1.10.bn1.weight\n",
      "layer1.10.bn1.bias\n",
      "layer1.10.bn1.running_mean\n",
      "layer1.10.bn1.running_var\n",
      "layer1.10.bn1.num_batches_tracked\n",
      "layer1.10.conv2.weight\n",
      "layer1.10.bn2.weight\n",
      "layer1.10.bn2.bias\n",
      "layer1.10.bn2.running_mean\n",
      "layer1.10.bn2.running_var\n",
      "layer1.10.bn2.num_batches_tracked\n",
      "layer1.11.conv1.weight\n",
      "layer1.11.bn1.weight\n",
      "layer1.11.bn1.bias\n",
      "layer1.11.bn1.running_mean\n",
      "layer1.11.bn1.running_var\n",
      "layer1.11.bn1.num_batches_tracked\n",
      "layer1.11.conv2.weight\n",
      "layer1.11.bn2.weight\n",
      "layer1.11.bn2.bias\n",
      "layer1.11.bn2.running_mean\n",
      "layer1.11.bn2.running_var\n",
      "layer1.11.bn2.num_batches_tracked\n",
      "layer1.12.conv1.weight\n",
      "layer1.12.bn1.weight\n",
      "layer1.12.bn1.bias\n",
      "layer1.12.bn1.running_mean\n",
      "layer1.12.bn1.running_var\n",
      "layer1.12.bn1.num_batches_tracked\n",
      "layer1.12.conv2.weight\n",
      "layer1.12.bn2.weight\n",
      "layer1.12.bn2.bias\n",
      "layer1.12.bn2.running_mean\n",
      "layer1.12.bn2.running_var\n",
      "layer1.12.bn2.num_batches_tracked\n",
      "layer1.13.conv1.weight\n",
      "layer1.13.bn1.weight\n",
      "layer1.13.bn1.bias\n",
      "layer1.13.bn1.running_mean\n",
      "layer1.13.bn1.running_var\n",
      "layer1.13.bn1.num_batches_tracked\n",
      "layer1.13.conv2.weight\n",
      "layer1.13.bn2.weight\n",
      "layer1.13.bn2.bias\n",
      "layer1.13.bn2.running_mean\n",
      "layer1.13.bn2.running_var\n",
      "layer1.13.bn2.num_batches_tracked\n",
      "layer1.14.conv1.weight\n",
      "layer1.14.bn1.weight\n",
      "layer1.14.bn1.bias\n",
      "layer1.14.bn1.running_mean\n",
      "layer1.14.bn1.running_var\n",
      "layer1.14.bn1.num_batches_tracked\n",
      "layer1.14.conv2.weight\n",
      "layer1.14.bn2.weight\n",
      "layer1.14.bn2.bias\n",
      "layer1.14.bn2.running_mean\n",
      "layer1.14.bn2.running_var\n",
      "layer1.14.bn2.num_batches_tracked\n",
      "layer1.15.conv1.weight\n",
      "layer1.15.bn1.weight\n",
      "layer1.15.bn1.bias\n",
      "layer1.15.bn1.running_mean\n",
      "layer1.15.bn1.running_var\n",
      "layer1.15.bn1.num_batches_tracked\n",
      "layer1.15.conv2.weight\n",
      "layer1.15.bn2.weight\n",
      "layer1.15.bn2.bias\n",
      "layer1.15.bn2.running_mean\n",
      "layer1.15.bn2.running_var\n",
      "layer1.15.bn2.num_batches_tracked\n",
      "layer1.16.conv1.weight\n",
      "layer1.16.bn1.weight\n",
      "layer1.16.bn1.bias\n",
      "layer1.16.bn1.running_mean\n",
      "layer1.16.bn1.running_var\n",
      "layer1.16.bn1.num_batches_tracked\n",
      "layer1.16.conv2.weight\n",
      "layer1.16.bn2.weight\n",
      "layer1.16.bn2.bias\n",
      "layer1.16.bn2.running_mean\n",
      "layer1.16.bn2.running_var\n",
      "layer1.16.bn2.num_batches_tracked\n",
      "layer1.17.conv1.weight\n",
      "layer1.17.bn1.weight\n",
      "layer1.17.bn1.bias\n",
      "layer1.17.bn1.running_mean\n",
      "layer1.17.bn1.running_var\n",
      "layer1.17.bn1.num_batches_tracked\n",
      "layer1.17.conv2.weight\n",
      "layer1.17.bn2.weight\n",
      "layer1.17.bn2.bias\n",
      "layer1.17.bn2.running_mean\n",
      "layer1.17.bn2.running_var\n",
      "layer1.17.bn2.num_batches_tracked\n",
      "layer2.0.conv1.weight\n",
      "layer2.0.bn1.weight\n",
      "layer2.0.bn1.bias\n",
      "layer2.0.bn1.running_mean\n",
      "layer2.0.bn1.running_var\n",
      "layer2.0.bn1.num_batches_tracked\n",
      "layer2.0.conv2.weight\n",
      "layer2.0.bn2.weight\n",
      "layer2.0.bn2.bias\n",
      "layer2.0.bn2.running_mean\n",
      "layer2.0.bn2.running_var\n",
      "layer2.0.bn2.num_batches_tracked\n",
      "layer2.1.conv1.weight\n",
      "layer2.1.bn1.weight\n",
      "layer2.1.bn1.bias\n",
      "layer2.1.bn1.running_mean\n",
      "layer2.1.bn1.running_var\n",
      "layer2.1.bn1.num_batches_tracked\n",
      "layer2.1.conv2.weight\n",
      "layer2.1.bn2.weight\n",
      "layer2.1.bn2.bias\n",
      "layer2.1.bn2.running_mean\n",
      "layer2.1.bn2.running_var\n",
      "layer2.1.bn2.num_batches_tracked\n",
      "layer2.2.conv1.weight\n",
      "layer2.2.bn1.weight\n",
      "layer2.2.bn1.bias\n",
      "layer2.2.bn1.running_mean\n",
      "layer2.2.bn1.running_var\n",
      "layer2.2.bn1.num_batches_tracked\n",
      "layer2.2.conv2.weight\n",
      "layer2.2.bn2.weight\n",
      "layer2.2.bn2.bias\n",
      "layer2.2.bn2.running_mean\n",
      "layer2.2.bn2.running_var\n",
      "layer2.2.bn2.num_batches_tracked\n",
      "layer2.3.conv1.weight\n",
      "layer2.3.bn1.weight\n",
      "layer2.3.bn1.bias\n",
      "layer2.3.bn1.running_mean\n",
      "layer2.3.bn1.running_var\n",
      "layer2.3.bn1.num_batches_tracked\n",
      "layer2.3.conv2.weight\n",
      "layer2.3.bn2.weight\n",
      "layer2.3.bn2.bias\n",
      "layer2.3.bn2.running_mean\n",
      "layer2.3.bn2.running_var\n",
      "layer2.3.bn2.num_batches_tracked\n",
      "layer2.4.conv1.weight\n",
      "layer2.4.bn1.weight\n",
      "layer2.4.bn1.bias\n",
      "layer2.4.bn1.running_mean\n",
      "layer2.4.bn1.running_var\n",
      "layer2.4.bn1.num_batches_tracked\n",
      "layer2.4.conv2.weight\n",
      "layer2.4.bn2.weight\n",
      "layer2.4.bn2.bias\n",
      "layer2.4.bn2.running_mean\n",
      "layer2.4.bn2.running_var\n",
      "layer2.4.bn2.num_batches_tracked\n",
      "layer2.5.conv1.weight\n",
      "layer2.5.bn1.weight\n",
      "layer2.5.bn1.bias\n",
      "layer2.5.bn1.running_mean\n",
      "layer2.5.bn1.running_var\n",
      "layer2.5.bn1.num_batches_tracked\n",
      "layer2.5.conv2.weight\n",
      "layer2.5.bn2.weight\n",
      "layer2.5.bn2.bias\n",
      "layer2.5.bn2.running_mean\n",
      "layer2.5.bn2.running_var\n",
      "layer2.5.bn2.num_batches_tracked\n",
      "layer2.6.conv1.weight\n",
      "layer2.6.bn1.weight\n",
      "layer2.6.bn1.bias\n",
      "layer2.6.bn1.running_mean\n",
      "layer2.6.bn1.running_var\n",
      "layer2.6.bn1.num_batches_tracked\n",
      "layer2.6.conv2.weight\n",
      "layer2.6.bn2.weight\n",
      "layer2.6.bn2.bias\n",
      "layer2.6.bn2.running_mean\n",
      "layer2.6.bn2.running_var\n",
      "layer2.6.bn2.num_batches_tracked\n",
      "layer2.7.conv1.weight\n",
      "layer2.7.bn1.weight\n",
      "layer2.7.bn1.bias\n",
      "layer2.7.bn1.running_mean\n",
      "layer2.7.bn1.running_var\n",
      "layer2.7.bn1.num_batches_tracked\n",
      "layer2.7.conv2.weight\n",
      "layer2.7.bn2.weight\n",
      "layer2.7.bn2.bias\n",
      "layer2.7.bn2.running_mean\n",
      "layer2.7.bn2.running_var\n",
      "layer2.7.bn2.num_batches_tracked\n",
      "layer2.8.conv1.weight\n",
      "layer2.8.bn1.weight\n",
      "layer2.8.bn1.bias\n",
      "layer2.8.bn1.running_mean\n",
      "layer2.8.bn1.running_var\n",
      "layer2.8.bn1.num_batches_tracked\n",
      "layer2.8.conv2.weight\n",
      "layer2.8.bn2.weight\n",
      "layer2.8.bn2.bias\n",
      "layer2.8.bn2.running_mean\n",
      "layer2.8.bn2.running_var\n",
      "layer2.8.bn2.num_batches_tracked\n",
      "layer2.9.conv1.weight\n",
      "layer2.9.bn1.weight\n",
      "layer2.9.bn1.bias\n",
      "layer2.9.bn1.running_mean\n",
      "layer2.9.bn1.running_var\n",
      "layer2.9.bn1.num_batches_tracked\n",
      "layer2.9.conv2.weight\n",
      "layer2.9.bn2.weight\n",
      "layer2.9.bn2.bias\n",
      "layer2.9.bn2.running_mean\n",
      "layer2.9.bn2.running_var\n",
      "layer2.9.bn2.num_batches_tracked\n",
      "layer2.10.conv1.weight\n",
      "layer2.10.bn1.weight\n",
      "layer2.10.bn1.bias\n",
      "layer2.10.bn1.running_mean\n",
      "layer2.10.bn1.running_var\n",
      "layer2.10.bn1.num_batches_tracked\n",
      "layer2.10.conv2.weight\n",
      "layer2.10.bn2.weight\n",
      "layer2.10.bn2.bias\n",
      "layer2.10.bn2.running_mean\n",
      "layer2.10.bn2.running_var\n",
      "layer2.10.bn2.num_batches_tracked\n",
      "layer2.11.conv1.weight\n",
      "layer2.11.bn1.weight\n",
      "layer2.11.bn1.bias\n",
      "layer2.11.bn1.running_mean\n",
      "layer2.11.bn1.running_var\n",
      "layer2.11.bn1.num_batches_tracked\n",
      "layer2.11.conv2.weight\n",
      "layer2.11.bn2.weight\n",
      "layer2.11.bn2.bias\n",
      "layer2.11.bn2.running_mean\n",
      "layer2.11.bn2.running_var\n",
      "layer2.11.bn2.num_batches_tracked\n",
      "layer2.12.conv1.weight\n",
      "layer2.12.bn1.weight\n",
      "layer2.12.bn1.bias\n",
      "layer2.12.bn1.running_mean\n",
      "layer2.12.bn1.running_var\n",
      "layer2.12.bn1.num_batches_tracked\n",
      "layer2.12.conv2.weight\n",
      "layer2.12.bn2.weight\n",
      "layer2.12.bn2.bias\n",
      "layer2.12.bn2.running_mean\n",
      "layer2.12.bn2.running_var\n",
      "layer2.12.bn2.num_batches_tracked\n",
      "layer2.13.conv1.weight\n",
      "layer2.13.bn1.weight\n",
      "layer2.13.bn1.bias\n",
      "layer2.13.bn1.running_mean\n",
      "layer2.13.bn1.running_var\n",
      "layer2.13.bn1.num_batches_tracked\n",
      "layer2.13.conv2.weight\n",
      "layer2.13.bn2.weight\n",
      "layer2.13.bn2.bias\n",
      "layer2.13.bn2.running_mean\n",
      "layer2.13.bn2.running_var\n",
      "layer2.13.bn2.num_batches_tracked\n",
      "layer2.14.conv1.weight\n",
      "layer2.14.bn1.weight\n",
      "layer2.14.bn1.bias\n",
      "layer2.14.bn1.running_mean\n",
      "layer2.14.bn1.running_var\n",
      "layer2.14.bn1.num_batches_tracked\n",
      "layer2.14.conv2.weight\n",
      "layer2.14.bn2.weight\n",
      "layer2.14.bn2.bias\n",
      "layer2.14.bn2.running_mean\n",
      "layer2.14.bn2.running_var\n",
      "layer2.14.bn2.num_batches_tracked\n",
      "layer2.15.conv1.weight\n",
      "layer2.15.bn1.weight\n",
      "layer2.15.bn1.bias\n",
      "layer2.15.bn1.running_mean\n",
      "layer2.15.bn1.running_var\n",
      "layer2.15.bn1.num_batches_tracked\n",
      "layer2.15.conv2.weight\n",
      "layer2.15.bn2.weight\n",
      "layer2.15.bn2.bias\n",
      "layer2.15.bn2.running_mean\n",
      "layer2.15.bn2.running_var\n",
      "layer2.15.bn2.num_batches_tracked\n",
      "layer2.16.conv1.weight\n",
      "layer2.16.bn1.weight\n",
      "layer2.16.bn1.bias\n",
      "layer2.16.bn1.running_mean\n",
      "layer2.16.bn1.running_var\n",
      "layer2.16.bn1.num_batches_tracked\n",
      "layer2.16.conv2.weight\n",
      "layer2.16.bn2.weight\n",
      "layer2.16.bn2.bias\n",
      "layer2.16.bn2.running_mean\n",
      "layer2.16.bn2.running_var\n",
      "layer2.16.bn2.num_batches_tracked\n",
      "layer2.17.conv1.weight\n",
      "layer2.17.bn1.weight\n",
      "layer2.17.bn1.bias\n",
      "layer2.17.bn1.running_mean\n",
      "layer2.17.bn1.running_var\n",
      "layer2.17.bn1.num_batches_tracked\n",
      "layer2.17.conv2.weight\n",
      "layer2.17.bn2.weight\n",
      "layer2.17.bn2.bias\n",
      "layer2.17.bn2.running_mean\n",
      "layer2.17.bn2.running_var\n",
      "layer2.17.bn2.num_batches_tracked\n",
      "layer3.0.conv1.weight\n",
      "layer3.0.bn1.weight\n",
      "layer3.0.bn1.bias\n",
      "layer3.0.bn1.running_mean\n",
      "layer3.0.bn1.running_var\n",
      "layer3.0.bn1.num_batches_tracked\n",
      "layer3.0.conv2.weight\n",
      "layer3.0.bn2.weight\n",
      "layer3.0.bn2.bias\n",
      "layer3.0.bn2.running_mean\n",
      "layer3.0.bn2.running_var\n",
      "layer3.0.bn2.num_batches_tracked\n",
      "layer3.1.conv1.weight\n",
      "layer3.1.bn1.weight\n",
      "layer3.1.bn1.bias\n",
      "layer3.1.bn1.running_mean\n",
      "layer3.1.bn1.running_var\n",
      "layer3.1.bn1.num_batches_tracked\n",
      "layer3.1.conv2.weight\n",
      "layer3.1.bn2.weight\n",
      "layer3.1.bn2.bias\n",
      "layer3.1.bn2.running_mean\n",
      "layer3.1.bn2.running_var\n",
      "layer3.1.bn2.num_batches_tracked\n",
      "layer3.2.conv1.weight\n",
      "layer3.2.bn1.weight\n",
      "layer3.2.bn1.bias\n",
      "layer3.2.bn1.running_mean\n",
      "layer3.2.bn1.running_var\n",
      "layer3.2.bn1.num_batches_tracked\n",
      "layer3.2.conv2.weight\n",
      "layer3.2.bn2.weight\n",
      "layer3.2.bn2.bias\n",
      "layer3.2.bn2.running_mean\n",
      "layer3.2.bn2.running_var\n",
      "layer3.2.bn2.num_batches_tracked\n",
      "layer3.3.conv1.weight\n",
      "layer3.3.bn1.weight\n",
      "layer3.3.bn1.bias\n",
      "layer3.3.bn1.running_mean\n",
      "layer3.3.bn1.running_var\n",
      "layer3.3.bn1.num_batches_tracked\n",
      "layer3.3.conv2.weight\n",
      "layer3.3.bn2.weight\n",
      "layer3.3.bn2.bias\n",
      "layer3.3.bn2.running_mean\n",
      "layer3.3.bn2.running_var\n",
      "layer3.3.bn2.num_batches_tracked\n",
      "layer3.4.conv1.weight\n",
      "layer3.4.bn1.weight\n",
      "layer3.4.bn1.bias\n",
      "layer3.4.bn1.running_mean\n",
      "layer3.4.bn1.running_var\n",
      "layer3.4.bn1.num_batches_tracked\n",
      "layer3.4.conv2.weight\n",
      "layer3.4.bn2.weight\n",
      "layer3.4.bn2.bias\n",
      "layer3.4.bn2.running_mean\n",
      "layer3.4.bn2.running_var\n",
      "layer3.4.bn2.num_batches_tracked\n",
      "layer3.5.conv1.weight\n",
      "layer3.5.bn1.weight\n",
      "layer3.5.bn1.bias\n",
      "layer3.5.bn1.running_mean\n",
      "layer3.5.bn1.running_var\n",
      "layer3.5.bn1.num_batches_tracked\n",
      "layer3.5.conv2.weight\n",
      "layer3.5.bn2.weight\n",
      "layer3.5.bn2.bias\n",
      "layer3.5.bn2.running_mean\n",
      "layer3.5.bn2.running_var\n",
      "layer3.5.bn2.num_batches_tracked\n",
      "layer3.6.conv1.weight\n",
      "layer3.6.bn1.weight\n",
      "layer3.6.bn1.bias\n",
      "layer3.6.bn1.running_mean\n",
      "layer3.6.bn1.running_var\n",
      "layer3.6.bn1.num_batches_tracked\n",
      "layer3.6.conv2.weight\n",
      "layer3.6.bn2.weight\n",
      "layer3.6.bn2.bias\n",
      "layer3.6.bn2.running_mean\n",
      "layer3.6.bn2.running_var\n",
      "layer3.6.bn2.num_batches_tracked\n",
      "layer3.7.conv1.weight\n",
      "layer3.7.bn1.weight\n",
      "layer3.7.bn1.bias\n",
      "layer3.7.bn1.running_mean\n",
      "layer3.7.bn1.running_var\n",
      "layer3.7.bn1.num_batches_tracked\n",
      "layer3.7.conv2.weight\n",
      "layer3.7.bn2.weight\n",
      "layer3.7.bn2.bias\n",
      "layer3.7.bn2.running_mean\n",
      "layer3.7.bn2.running_var\n",
      "layer3.7.bn2.num_batches_tracked\n",
      "layer3.8.conv1.weight\n",
      "layer3.8.bn1.weight\n",
      "layer3.8.bn1.bias\n",
      "layer3.8.bn1.running_mean\n",
      "layer3.8.bn1.running_var\n",
      "layer3.8.bn1.num_batches_tracked\n",
      "layer3.8.conv2.weight\n",
      "layer3.8.bn2.weight\n",
      "layer3.8.bn2.bias\n",
      "layer3.8.bn2.running_mean\n",
      "layer3.8.bn2.running_var\n",
      "layer3.8.bn2.num_batches_tracked\n",
      "layer3.9.conv1.weight\n",
      "layer3.9.bn1.weight\n",
      "layer3.9.bn1.bias\n",
      "layer3.9.bn1.running_mean\n",
      "layer3.9.bn1.running_var\n",
      "layer3.9.bn1.num_batches_tracked\n",
      "layer3.9.conv2.weight\n",
      "layer3.9.bn2.weight\n",
      "layer3.9.bn2.bias\n",
      "layer3.9.bn2.running_mean\n",
      "layer3.9.bn2.running_var\n",
      "layer3.9.bn2.num_batches_tracked\n",
      "layer3.10.conv1.weight\n",
      "layer3.10.bn1.weight\n",
      "layer3.10.bn1.bias\n",
      "layer3.10.bn1.running_mean\n",
      "layer3.10.bn1.running_var\n",
      "layer3.10.bn1.num_batches_tracked\n",
      "layer3.10.conv2.weight\n",
      "layer3.10.bn2.weight\n",
      "layer3.10.bn2.bias\n",
      "layer3.10.bn2.running_mean\n",
      "layer3.10.bn2.running_var\n",
      "layer3.10.bn2.num_batches_tracked\n",
      "layer3.11.conv1.weight\n",
      "layer3.11.bn1.weight\n",
      "layer3.11.bn1.bias\n",
      "layer3.11.bn1.running_mean\n",
      "layer3.11.bn1.running_var\n",
      "layer3.11.bn1.num_batches_tracked\n",
      "layer3.11.conv2.weight\n",
      "layer3.11.bn2.weight\n",
      "layer3.11.bn2.bias\n",
      "layer3.11.bn2.running_mean\n",
      "layer3.11.bn2.running_var\n",
      "layer3.11.bn2.num_batches_tracked\n",
      "layer3.12.conv1.weight\n",
      "layer3.12.bn1.weight\n",
      "layer3.12.bn1.bias\n",
      "layer3.12.bn1.running_mean\n",
      "layer3.12.bn1.running_var\n",
      "layer3.12.bn1.num_batches_tracked\n",
      "layer3.12.conv2.weight\n",
      "layer3.12.bn2.weight\n",
      "layer3.12.bn2.bias\n",
      "layer3.12.bn2.running_mean\n",
      "layer3.12.bn2.running_var\n",
      "layer3.12.bn2.num_batches_tracked\n",
      "layer3.13.conv1.weight\n",
      "layer3.13.bn1.weight\n",
      "layer3.13.bn1.bias\n",
      "layer3.13.bn1.running_mean\n",
      "layer3.13.bn1.running_var\n",
      "layer3.13.bn1.num_batches_tracked\n",
      "layer3.13.conv2.weight\n",
      "layer3.13.bn2.weight\n",
      "layer3.13.bn2.bias\n",
      "layer3.13.bn2.running_mean\n",
      "layer3.13.bn2.running_var\n",
      "layer3.13.bn2.num_batches_tracked\n",
      "layer3.14.conv1.weight\n",
      "layer3.14.bn1.weight\n",
      "layer3.14.bn1.bias\n",
      "layer3.14.bn1.running_mean\n",
      "layer3.14.bn1.running_var\n",
      "layer3.14.bn1.num_batches_tracked\n",
      "layer3.14.conv2.weight\n",
      "layer3.14.bn2.weight\n",
      "layer3.14.bn2.bias\n",
      "layer3.14.bn2.running_mean\n",
      "layer3.14.bn2.running_var\n",
      "layer3.14.bn2.num_batches_tracked\n",
      "layer3.15.conv1.weight\n",
      "layer3.15.bn1.weight\n",
      "layer3.15.bn1.bias\n",
      "layer3.15.bn1.running_mean\n",
      "layer3.15.bn1.running_var\n",
      "layer3.15.bn1.num_batches_tracked\n",
      "layer3.15.conv2.weight\n",
      "layer3.15.bn2.weight\n",
      "layer3.15.bn2.bias\n",
      "layer3.15.bn2.running_mean\n",
      "layer3.15.bn2.running_var\n",
      "layer3.15.bn2.num_batches_tracked\n",
      "layer3.16.conv1.weight\n",
      "layer3.16.bn1.weight\n",
      "layer3.16.bn1.bias\n",
      "layer3.16.bn1.running_mean\n",
      "layer3.16.bn1.running_var\n",
      "layer3.16.bn1.num_batches_tracked\n",
      "layer3.16.conv2.weight\n",
      "layer3.16.bn2.weight\n",
      "layer3.16.bn2.bias\n",
      "layer3.16.bn2.running_mean\n",
      "layer3.16.bn2.running_var\n",
      "layer3.16.bn2.num_batches_tracked\n",
      "layer3.17.conv1.weight\n",
      "layer3.17.bn1.weight\n",
      "layer3.17.bn1.bias\n",
      "layer3.17.bn1.running_mean\n",
      "layer3.17.bn1.running_var\n",
      "layer3.17.bn1.num_batches_tracked\n",
      "layer3.17.conv2.weight\n",
      "layer3.17.bn2.weight\n",
      "layer3.17.bn2.bias\n",
      "layer3.17.bn2.running_mean\n",
      "layer3.17.bn2.running_var\n",
      "layer3.17.bn2.num_batches_tracked\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.state_dict().items(): #.named_modules():#\n",
    "    print(name)\n",
    "    # name: str\n",
    "    # param: Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inplanes #64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compute_flops import print_model_param_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             432\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "              ReLU-3           [-1, 16, 32, 32]               0\n",
      "            Conv2d-4           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-5           [-1, 16, 32, 32]              32\n",
      "              ReLU-6           [-1, 16, 32, 32]               0\n",
      "            Conv2d-7           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-8           [-1, 16, 32, 32]              32\n",
      "              ReLU-9           [-1, 16, 32, 32]               0\n",
      "       BasicBlock-10           [-1, 16, 32, 32]               0\n",
      "           Conv2d-11           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-12           [-1, 16, 32, 32]              32\n",
      "             ReLU-13           [-1, 16, 32, 32]               0\n",
      "           Conv2d-14           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-15           [-1, 16, 32, 32]              32\n",
      "             ReLU-16           [-1, 16, 32, 32]               0\n",
      "       BasicBlock-17           [-1, 16, 32, 32]               0\n",
      "           Conv2d-18           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 16, 32, 32]              32\n",
      "             ReLU-20           [-1, 16, 32, 32]               0\n",
      "           Conv2d-21           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-22           [-1, 16, 32, 32]              32\n",
      "             ReLU-23           [-1, 16, 32, 32]               0\n",
      "       BasicBlock-24           [-1, 16, 32, 32]               0\n",
      "           Conv2d-25           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-26           [-1, 16, 32, 32]              32\n",
      "             ReLU-27           [-1, 16, 32, 32]               0\n",
      "           Conv2d-28           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-29           [-1, 16, 32, 32]              32\n",
      "             ReLU-30           [-1, 16, 32, 32]               0\n",
      "       BasicBlock-31           [-1, 16, 32, 32]               0\n",
      "           Conv2d-32           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-33           [-1, 16, 32, 32]              32\n",
      "             ReLU-34           [-1, 16, 32, 32]               0\n",
      "           Conv2d-35           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-36           [-1, 16, 32, 32]              32\n",
      "             ReLU-37           [-1, 16, 32, 32]               0\n",
      "       BasicBlock-38           [-1, 16, 32, 32]               0\n",
      "           Conv2d-39           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-40           [-1, 16, 32, 32]              32\n",
      "             ReLU-41           [-1, 16, 32, 32]               0\n",
      "           Conv2d-42           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-43           [-1, 16, 32, 32]              32\n",
      "             ReLU-44           [-1, 16, 32, 32]               0\n",
      "       BasicBlock-45           [-1, 16, 32, 32]               0\n",
      "           Conv2d-46           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-47           [-1, 16, 32, 32]              32\n",
      "             ReLU-48           [-1, 16, 32, 32]               0\n",
      "           Conv2d-49           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-50           [-1, 16, 32, 32]              32\n",
      "             ReLU-51           [-1, 16, 32, 32]               0\n",
      "       BasicBlock-52           [-1, 16, 32, 32]               0\n",
      "           Conv2d-53           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-54           [-1, 16, 32, 32]              32\n",
      "             ReLU-55           [-1, 16, 32, 32]               0\n",
      "           Conv2d-56           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-57           [-1, 16, 32, 32]              32\n",
      "             ReLU-58           [-1, 16, 32, 32]               0\n",
      "       BasicBlock-59           [-1, 16, 32, 32]               0\n",
      "           Conv2d-60           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-61           [-1, 16, 32, 32]              32\n",
      "             ReLU-62           [-1, 16, 32, 32]               0\n",
      "           Conv2d-63           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-64           [-1, 16, 32, 32]              32\n",
      "             ReLU-65           [-1, 16, 32, 32]               0\n",
      "       BasicBlock-66           [-1, 16, 32, 32]               0\n",
      "           Conv2d-67           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-68           [-1, 16, 32, 32]              32\n",
      "             ReLU-69           [-1, 16, 32, 32]               0\n",
      "           Conv2d-70           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-71           [-1, 16, 32, 32]              32\n",
      "             ReLU-72           [-1, 16, 32, 32]               0\n",
      "       BasicBlock-73           [-1, 16, 32, 32]               0\n",
      "           Conv2d-74           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-75           [-1, 16, 32, 32]              32\n",
      "             ReLU-76           [-1, 16, 32, 32]               0\n",
      "           Conv2d-77           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-78           [-1, 16, 32, 32]              32\n",
      "             ReLU-79           [-1, 16, 32, 32]               0\n",
      "       BasicBlock-80           [-1, 16, 32, 32]               0\n",
      "           Conv2d-81           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-82           [-1, 16, 32, 32]              32\n",
      "             ReLU-83           [-1, 16, 32, 32]               0\n",
      "           Conv2d-84           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-85           [-1, 16, 32, 32]              32\n",
      "             ReLU-86           [-1, 16, 32, 32]               0\n",
      "       BasicBlock-87           [-1, 16, 32, 32]               0\n",
      "           Conv2d-88           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-89           [-1, 16, 32, 32]              32\n",
      "             ReLU-90           [-1, 16, 32, 32]               0\n",
      "           Conv2d-91           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-92           [-1, 16, 32, 32]              32\n",
      "             ReLU-93           [-1, 16, 32, 32]               0\n",
      "       BasicBlock-94           [-1, 16, 32, 32]               0\n",
      "           Conv2d-95           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-96           [-1, 16, 32, 32]              32\n",
      "             ReLU-97           [-1, 16, 32, 32]               0\n",
      "           Conv2d-98           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-99           [-1, 16, 32, 32]              32\n",
      "            ReLU-100           [-1, 16, 32, 32]               0\n",
      "      BasicBlock-101           [-1, 16, 32, 32]               0\n",
      "          Conv2d-102           [-1, 16, 32, 32]           2,304\n",
      "     BatchNorm2d-103           [-1, 16, 32, 32]              32\n",
      "            ReLU-104           [-1, 16, 32, 32]               0\n",
      "          Conv2d-105           [-1, 16, 32, 32]           2,304\n",
      "     BatchNorm2d-106           [-1, 16, 32, 32]              32\n",
      "            ReLU-107           [-1, 16, 32, 32]               0\n",
      "      BasicBlock-108           [-1, 16, 32, 32]               0\n",
      "          Conv2d-109           [-1, 16, 32, 32]           2,304\n",
      "     BatchNorm2d-110           [-1, 16, 32, 32]              32\n",
      "            ReLU-111           [-1, 16, 32, 32]               0\n",
      "          Conv2d-112           [-1, 16, 32, 32]           2,304\n",
      "     BatchNorm2d-113           [-1, 16, 32, 32]              32\n",
      "            ReLU-114           [-1, 16, 32, 32]               0\n",
      "      BasicBlock-115           [-1, 16, 32, 32]               0\n",
      "          Conv2d-116           [-1, 16, 32, 32]           2,304\n",
      "     BatchNorm2d-117           [-1, 16, 32, 32]              32\n",
      "            ReLU-118           [-1, 16, 32, 32]               0\n",
      "          Conv2d-119           [-1, 16, 32, 32]           2,304\n",
      "     BatchNorm2d-120           [-1, 16, 32, 32]              32\n",
      "            ReLU-121           [-1, 16, 32, 32]               0\n",
      "      BasicBlock-122           [-1, 16, 32, 32]               0\n",
      "          Conv2d-123           [-1, 16, 32, 32]           2,304\n",
      "     BatchNorm2d-124           [-1, 16, 32, 32]              32\n",
      "            ReLU-125           [-1, 16, 32, 32]               0\n",
      "          Conv2d-126           [-1, 16, 32, 32]           2,304\n",
      "     BatchNorm2d-127           [-1, 16, 32, 32]              32\n",
      "            ReLU-128           [-1, 16, 32, 32]               0\n",
      "      BasicBlock-129           [-1, 16, 32, 32]               0\n",
      "          Conv2d-130           [-1, 32, 16, 16]           4,608\n",
      "     BatchNorm2d-131           [-1, 32, 16, 16]              64\n",
      "            ReLU-132           [-1, 32, 16, 16]               0\n",
      "          Conv2d-133           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-134           [-1, 32, 16, 16]              64\n",
      "            ReLU-135           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-136           [-1, 32, 16, 16]               0\n",
      "          Conv2d-137           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-138           [-1, 32, 16, 16]              64\n",
      "            ReLU-139           [-1, 32, 16, 16]               0\n",
      "          Conv2d-140           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-141           [-1, 32, 16, 16]              64\n",
      "            ReLU-142           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-143           [-1, 32, 16, 16]               0\n",
      "          Conv2d-144           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-145           [-1, 32, 16, 16]              64\n",
      "            ReLU-146           [-1, 32, 16, 16]               0\n",
      "          Conv2d-147           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-148           [-1, 32, 16, 16]              64\n",
      "            ReLU-149           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-150           [-1, 32, 16, 16]               0\n",
      "          Conv2d-151           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-152           [-1, 32, 16, 16]              64\n",
      "            ReLU-153           [-1, 32, 16, 16]               0\n",
      "          Conv2d-154           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-155           [-1, 32, 16, 16]              64\n",
      "            ReLU-156           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-157           [-1, 32, 16, 16]               0\n",
      "          Conv2d-158           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-159           [-1, 32, 16, 16]              64\n",
      "            ReLU-160           [-1, 32, 16, 16]               0\n",
      "          Conv2d-161           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-162           [-1, 32, 16, 16]              64\n",
      "            ReLU-163           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-164           [-1, 32, 16, 16]               0\n",
      "          Conv2d-165           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-166           [-1, 32, 16, 16]              64\n",
      "            ReLU-167           [-1, 32, 16, 16]               0\n",
      "          Conv2d-168           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-169           [-1, 32, 16, 16]              64\n",
      "            ReLU-170           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-171           [-1, 32, 16, 16]               0\n",
      "          Conv2d-172           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-173           [-1, 32, 16, 16]              64\n",
      "            ReLU-174           [-1, 32, 16, 16]               0\n",
      "          Conv2d-175           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-176           [-1, 32, 16, 16]              64\n",
      "            ReLU-177           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-178           [-1, 32, 16, 16]               0\n",
      "          Conv2d-179           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-180           [-1, 32, 16, 16]              64\n",
      "            ReLU-181           [-1, 32, 16, 16]               0\n",
      "          Conv2d-182           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-183           [-1, 32, 16, 16]              64\n",
      "            ReLU-184           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-185           [-1, 32, 16, 16]               0\n",
      "          Conv2d-186           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-187           [-1, 32, 16, 16]              64\n",
      "            ReLU-188           [-1, 32, 16, 16]               0\n",
      "          Conv2d-189           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-190           [-1, 32, 16, 16]              64\n",
      "            ReLU-191           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-192           [-1, 32, 16, 16]               0\n",
      "          Conv2d-193           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-194           [-1, 32, 16, 16]              64\n",
      "            ReLU-195           [-1, 32, 16, 16]               0\n",
      "          Conv2d-196           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-197           [-1, 32, 16, 16]              64\n",
      "            ReLU-198           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-199           [-1, 32, 16, 16]               0\n",
      "          Conv2d-200           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-201           [-1, 32, 16, 16]              64\n",
      "            ReLU-202           [-1, 32, 16, 16]               0\n",
      "          Conv2d-203           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-204           [-1, 32, 16, 16]              64\n",
      "            ReLU-205           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-206           [-1, 32, 16, 16]               0\n",
      "          Conv2d-207           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-208           [-1, 32, 16, 16]              64\n",
      "            ReLU-209           [-1, 32, 16, 16]               0\n",
      "          Conv2d-210           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-211           [-1, 32, 16, 16]              64\n",
      "            ReLU-212           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-213           [-1, 32, 16, 16]               0\n",
      "          Conv2d-214           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-215           [-1, 32, 16, 16]              64\n",
      "            ReLU-216           [-1, 32, 16, 16]               0\n",
      "          Conv2d-217           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-218           [-1, 32, 16, 16]              64\n",
      "            ReLU-219           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-220           [-1, 32, 16, 16]               0\n",
      "          Conv2d-221           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-222           [-1, 32, 16, 16]              64\n",
      "            ReLU-223           [-1, 32, 16, 16]               0\n",
      "          Conv2d-224           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-225           [-1, 32, 16, 16]              64\n",
      "            ReLU-226           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-227           [-1, 32, 16, 16]               0\n",
      "          Conv2d-228           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-229           [-1, 32, 16, 16]              64\n",
      "            ReLU-230           [-1, 32, 16, 16]               0\n",
      "          Conv2d-231           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-232           [-1, 32, 16, 16]              64\n",
      "            ReLU-233           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-234           [-1, 32, 16, 16]               0\n",
      "          Conv2d-235           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-236           [-1, 32, 16, 16]              64\n",
      "            ReLU-237           [-1, 32, 16, 16]               0\n",
      "          Conv2d-238           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-239           [-1, 32, 16, 16]              64\n",
      "            ReLU-240           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-241           [-1, 32, 16, 16]               0\n",
      "          Conv2d-242           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-243           [-1, 32, 16, 16]              64\n",
      "            ReLU-244           [-1, 32, 16, 16]               0\n",
      "          Conv2d-245           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-246           [-1, 32, 16, 16]              64\n",
      "            ReLU-247           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-248           [-1, 32, 16, 16]               0\n",
      "          Conv2d-249           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-250           [-1, 32, 16, 16]              64\n",
      "            ReLU-251           [-1, 32, 16, 16]               0\n",
      "          Conv2d-252           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-253           [-1, 32, 16, 16]              64\n",
      "            ReLU-254           [-1, 32, 16, 16]               0\n",
      "      BasicBlock-255           [-1, 32, 16, 16]               0\n",
      "          Conv2d-256             [-1, 64, 8, 8]          18,432\n",
      "     BatchNorm2d-257             [-1, 64, 8, 8]             128\n",
      "            ReLU-258             [-1, 64, 8, 8]               0\n",
      "          Conv2d-259             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-260             [-1, 64, 8, 8]             128\n",
      "            ReLU-261             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-262             [-1, 64, 8, 8]               0\n",
      "          Conv2d-263             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-264             [-1, 64, 8, 8]             128\n",
      "            ReLU-265             [-1, 64, 8, 8]               0\n",
      "          Conv2d-266             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-267             [-1, 64, 8, 8]             128\n",
      "            ReLU-268             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-269             [-1, 64, 8, 8]               0\n",
      "          Conv2d-270             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-271             [-1, 64, 8, 8]             128\n",
      "            ReLU-272             [-1, 64, 8, 8]               0\n",
      "          Conv2d-273             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-274             [-1, 64, 8, 8]             128\n",
      "            ReLU-275             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-276             [-1, 64, 8, 8]               0\n",
      "          Conv2d-277             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-278             [-1, 64, 8, 8]             128\n",
      "            ReLU-279             [-1, 64, 8, 8]               0\n",
      "          Conv2d-280             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-281             [-1, 64, 8, 8]             128\n",
      "            ReLU-282             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-283             [-1, 64, 8, 8]               0\n",
      "          Conv2d-284             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-285             [-1, 64, 8, 8]             128\n",
      "            ReLU-286             [-1, 64, 8, 8]               0\n",
      "          Conv2d-287             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-288             [-1, 64, 8, 8]             128\n",
      "            ReLU-289             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-290             [-1, 64, 8, 8]               0\n",
      "          Conv2d-291             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-292             [-1, 64, 8, 8]             128\n",
      "            ReLU-293             [-1, 64, 8, 8]               0\n",
      "          Conv2d-294             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-295             [-1, 64, 8, 8]             128\n",
      "            ReLU-296             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-297             [-1, 64, 8, 8]               0\n",
      "          Conv2d-298             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-299             [-1, 64, 8, 8]             128\n",
      "            ReLU-300             [-1, 64, 8, 8]               0\n",
      "          Conv2d-301             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-302             [-1, 64, 8, 8]             128\n",
      "            ReLU-303             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-304             [-1, 64, 8, 8]               0\n",
      "          Conv2d-305             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-306             [-1, 64, 8, 8]             128\n",
      "            ReLU-307             [-1, 64, 8, 8]               0\n",
      "          Conv2d-308             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-309             [-1, 64, 8, 8]             128\n",
      "            ReLU-310             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-311             [-1, 64, 8, 8]               0\n",
      "          Conv2d-312             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-313             [-1, 64, 8, 8]             128\n",
      "            ReLU-314             [-1, 64, 8, 8]               0\n",
      "          Conv2d-315             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-316             [-1, 64, 8, 8]             128\n",
      "            ReLU-317             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-318             [-1, 64, 8, 8]               0\n",
      "          Conv2d-319             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-320             [-1, 64, 8, 8]             128\n",
      "            ReLU-321             [-1, 64, 8, 8]               0\n",
      "          Conv2d-322             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-323             [-1, 64, 8, 8]             128\n",
      "            ReLU-324             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-325             [-1, 64, 8, 8]               0\n",
      "          Conv2d-326             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-327             [-1, 64, 8, 8]             128\n",
      "            ReLU-328             [-1, 64, 8, 8]               0\n",
      "          Conv2d-329             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-330             [-1, 64, 8, 8]             128\n",
      "            ReLU-331             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-332             [-1, 64, 8, 8]               0\n",
      "          Conv2d-333             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-334             [-1, 64, 8, 8]             128\n",
      "            ReLU-335             [-1, 64, 8, 8]               0\n",
      "          Conv2d-336             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-337             [-1, 64, 8, 8]             128\n",
      "            ReLU-338             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-339             [-1, 64, 8, 8]               0\n",
      "          Conv2d-340             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-341             [-1, 64, 8, 8]             128\n",
      "            ReLU-342             [-1, 64, 8, 8]               0\n",
      "          Conv2d-343             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-344             [-1, 64, 8, 8]             128\n",
      "            ReLU-345             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-346             [-1, 64, 8, 8]               0\n",
      "          Conv2d-347             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-348             [-1, 64, 8, 8]             128\n",
      "            ReLU-349             [-1, 64, 8, 8]               0\n",
      "          Conv2d-350             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-351             [-1, 64, 8, 8]             128\n",
      "            ReLU-352             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-353             [-1, 64, 8, 8]               0\n",
      "          Conv2d-354             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-355             [-1, 64, 8, 8]             128\n",
      "            ReLU-356             [-1, 64, 8, 8]               0\n",
      "          Conv2d-357             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-358             [-1, 64, 8, 8]             128\n",
      "            ReLU-359             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-360             [-1, 64, 8, 8]               0\n",
      "          Conv2d-361             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-362             [-1, 64, 8, 8]             128\n",
      "            ReLU-363             [-1, 64, 8, 8]               0\n",
      "          Conv2d-364             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-365             [-1, 64, 8, 8]             128\n",
      "            ReLU-366             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-367             [-1, 64, 8, 8]               0\n",
      "          Conv2d-368             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-369             [-1, 64, 8, 8]             128\n",
      "            ReLU-370             [-1, 64, 8, 8]               0\n",
      "          Conv2d-371             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-372             [-1, 64, 8, 8]             128\n",
      "            ReLU-373             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-374             [-1, 64, 8, 8]               0\n",
      "          Conv2d-375             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-376             [-1, 64, 8, 8]             128\n",
      "            ReLU-377             [-1, 64, 8, 8]               0\n",
      "          Conv2d-378             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-379             [-1, 64, 8, 8]             128\n",
      "            ReLU-380             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-381             [-1, 64, 8, 8]               0\n",
      "       AvgPool2d-382             [-1, 64, 1, 1]               0\n",
      "          Linear-383                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 1,727,962\n",
      "Trainable params: 1,727,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 27.94\n",
      "Params size (MB): 6.59\n",
      "Estimated Total Size (MB): 34.54\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model = model.cuda()\n",
    "summary(model, input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = {\n",
    "    'A': [36],\n",
    "    'B': [36, 38, 74],\n",
    "}\n",
    "\n",
    "prune_prob = {\n",
    "    'A': [0.5, 0.0, 0.0],\n",
    "    'B': [0.5, 0.4, 0.3],\n",
    "}\n",
    "\n",
    "layer_id = 1\n",
    "cfg = []\n",
    "cfg_mask = []\n",
    "stage = 0\n",
    "prune_prob_stage = prune_prob['B'][stage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.])\n",
      "[tensor([0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.]), tensor([1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.])]\n",
      "[8, 8]\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.])\n",
      "[tensor([0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.]), tensor([1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.]), tensor([0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.])]\n",
      "[8, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        out_channels = m.weight.data.shape[0]\n",
    "#         print(m,'-', m.weight.data.shape,'->', out_channels)\n",
    "        \n",
    "        #skip---------\n",
    "#         cfg_mask.append(torch.ones(out_channels)) #一個空的 裡面都存1的matrix\n",
    "#         cfg.append(out_channels)\n",
    "#         layer_id += 1\n",
    "#         print(cfg_mask)\n",
    "#         print(cfg)\n",
    "#         print('')\n",
    "        \n",
    "        #.clone(): 複製一個完全相同的tensor\n",
    "        #.cpu(): gpu tensor 轉 cpu tensor\n",
    "        #.numpy(): tensor 轉 numpy\n",
    "        weight_copy = m.weight.data.abs().clone().cpu().numpy()\n",
    "#         print(len(weight_copy)) # k 3*3, 3channel, output channel 16\n",
    "#         print(weight_copy)\n",
    "        L1_norm = np.sum(weight_copy, axis=(1,2,3))\n",
    "#         print(L1_norm)\n",
    "        num_keep = int(out_channels * (1 - prune_prob_stage))\n",
    "#         print(num_keep) #8\n",
    "        arg_max = np.argsort(L1_norm) #x中的元素從小到大排列，提取其對應的index(索引)，然後輸出到y\n",
    "#         print(arg_max)\n",
    "        arg_max_rev = arg_max[::-1][:num_keep]\n",
    "#         print(arg_max_rev)\n",
    "        mask = torch.zeros(out_channels)\n",
    "#         print(mask)\n",
    "        mask[arg_max_rev.tolist()] = 1\n",
    "        print(mask)\n",
    "        cfg_mask.append(mask)\n",
    "        cfg.append(num_keep)\n",
    "        print(cfg_mask)\n",
    "        print(cfg)\n",
    "        i+=1\n",
    "        if i == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "           p  p  p  p  p\n",
    "            o  o  o  o  o\n",
    "            s  s  s  s  s\n",
    "\n",
    "     dim 2  0  1  2  3  4\n",
    "\n",
    "            |  |  |  |  |\n",
    "  dim 0     ↓  ↓  ↓  ↓  ↓\n",
    "  ----> [[[ 0  1  2  3  4]   <---- dim 1, pos 0\n",
    "  pos 0   [ 5  6  7  8  9]   <---- dim 1, pos 1\n",
    "          [10 11 12 13 14]]  <---- dim 1, pos 2\n",
    "  dim 0\n",
    "  ---->  [[15 16 17 18 19]   <---- dim 1, pos 0\n",
    "  pos 1   [20 21 22 23 24]   <---- dim 1, pos 1\n",
    "          [25 26 27 28 29]]] <---- dim 1, pos 2\n",
    "            ↑  ↑  ↑  ↑  ↑\n",
    "            |  |  |  |  |\n",
    "\n",
    "     dim 2  p  p  p  p  p\n",
    "            o  o  o  o  o\n",
    "            s  s  s  s  s\n",
    "\n",
    "            0  1  2  3  4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_refine = '/home/jovyan/model_compression/rethinking-network-pruning/cifar/l1-norm-pruning/logs/pruned.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(args_refine)\n",
    "newmodel = models.__dict__[args_arch](dataset=args_dataset, depth=args_depth, cfg=checkpoint['cfg'])\n",
    "newmodel.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_mask = torch.ones(3)\n",
    "layer_id_in_cfg = 0\n",
    "conv_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 conv1\n",
      "2 layer1.0.conv1\n",
      "3 layer1.0.conv2\n",
      "tensor([0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.])\n",
      "2 layer1.1.conv1\n",
      "3 layer1.1.conv2\n",
      "tensor([1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.])\n",
      "2 layer1.2.conv1\n",
      "3 layer1.2.conv2\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.])\n",
      "2 layer1.3.conv1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-36a3e252217e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconv_count\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_id_in_cfg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#             print(mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "start_mask = torch.ones(3)\n",
    "layer_id_in_cfg = 0\n",
    "conv_count = 1\n",
    "for [m0, m1, (name,layer)] in zip(model.modules(), newmodel.modules(),  (model.named_modules())):\n",
    "    if isinstance(m0, nn.Conv2d):\n",
    "        if conv_count == 1:\n",
    "            print('1', name)\n",
    "            m1.weight.data = m0.weight.data.clone()\n",
    "            conv_count += 1\n",
    "            continue\n",
    "        if conv_count % 2 == 0:\n",
    "            print('2', name)\n",
    "            mask = cfg_mask[layer_id_in_cfg]\n",
    "#             print(mask)\n",
    "            idx = np.squeeze(np.argwhere(np.asarray(mask.cpu().numpy())))\n",
    "#             print(idx)\n",
    "            w = m0.weight.data[idx.tolist(), :, :, :].clone()\n",
    "#             print(m0.weight.data[idx.tolist()].shape)\n",
    "            m1.weight.data = w.clone()\n",
    "            layer_id_in_cfg += 1 #+\n",
    "            conv_count += 1\n",
    "            continue\n",
    "        if conv_count % 2 == 1:\n",
    "            print('3', name)\n",
    "            mask = cfg_mask[layer_id_in_cfg-1]\n",
    "            print(mask)\n",
    "            conv_count += 1\n",
    "            continue\n",
    "    i+=1\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx0 = [0]\n",
    "idx1 = np.resize(idx0, (1,))\n",
    "idx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
